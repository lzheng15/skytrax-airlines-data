{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skytrax Airline User Reviews\n",
    "\n",
    "#### Table of Contents:\n",
    "Data cleaning<br>\n",
    "Exploratory data analysis<br>\n",
    "NLP on reviewer comments using NLTK and Scikit-learn<br>\n",
    "Data analysis on airline ratings data<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background:\n",
    "Customer sentiment plays a significant role in how people perceive airlines and may influence whether they recommend the airline to someone else. Additionally, a large number of unfavorable reviews can bring uncomfortable media attention and cause public relations issues. Our goal is to use Natural Language Processing (NLP) on reviewer comments in the Skytrax Airlines User Reviews dataset to predict if a reviewer would recommend an airline based on what they wrote.<br>\n",
    "<br>\n",
    "Skytrax data can be found here: https://github.com/quankiquanki/skytrax-reviews-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and data cleaning\n",
    "Importing packages, reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your packages you need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to import the airline skytrax data that you saved to your computer\n",
    "airline=pd.read_csv(r'C:\\Users\\Laura\\Documents\\Learning Python\\Skytrax airline data\\data\\airline.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out the data to see what it looks like\n",
    "airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#taking a look at the columns\n",
    "airline.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset your data to just the variables we need \n",
    "airline=airline[['airline_name', 'title', 'author', 'author_country', 'date', 'content', \n",
    "                   'cabin_flown', 'overall_rating', 'value_money_rating', 'recommended']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date to datetime, check out min and max\n",
    "airline['date'] = pd.to_datetime(airline['date'])\n",
    "print(airline['date'].min())  #looks at our dates\n",
    "print(airline['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have missing data for several of these variables so we will need to drop them\n",
    "print(\"we are now dropping missings and saving in a new dataset called airline_completecase\")\n",
    "airline_completecase = airline.dropna()\n",
    "#how many rows?\n",
    "print('we have '+ str(len(airline_completecase)) + ' complete case observations in this subset')\n",
    "\n",
    "#convert overall rating and value money rating to int\n",
    "airline_completecase.overall_rating=airline_completecase.overall_rating.astype(int)\n",
    "airline_completecase.value_money_rating=airline_completecase.value_money_rating.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make a No/Yes variable for recommended\n",
    "airline_completecase['rec'] = np.where(airline_completecase['recommended']==1, 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply length of message data set\n",
    "airline_completecase['length'] = airline_completecase['content'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#information about our dataset\n",
    "airline_completecase.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#information about our dataset \n",
    "airline_completecase.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_completecase.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check out airlines complete case \n",
    "airline_completecase.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "This test size is 30% of the dataset (10410 obs) and the training set is the rest (24269 obs). Note: This is the default split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train/test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "msg_train, msg_test, label_train, label_test = \\\n",
    "train_test_split(airline_completecase['content'], airline_completecase['rec'], test_size=0.3)\n",
    "\n",
    "print('training set: '  + str(len(msg_train)) + ' obs')\n",
    "print('test set: '+ str(len(msg_test)) + ' obs' )\n",
    "print('combined: ' + str(len(msg_train) + len(msg_test))  + ' obs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "We will do some exploratory data analysis on this text stuff to see what we can learn about the relationship between the reviews and whether or not the reviewer recommends the airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countplot of recommended (0=no, 1=yes)\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax=sns.countplot(x='recommended', data=airline_completecase)\n",
    "ax.set_title(\"Recommend Airline?\")\n",
    "ax.set_xticklabels([\"No\",\"Yes\"])\n",
    "ax.set_xlabel(\" \")\n",
    "ax.set_ylabel(\"Number of Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating by recommend or not. This is obviously expected\n",
    "sns.set(style=\"darkgrid\")\n",
    "g = sns.FacetGrid(airline_completecase, col=\"recommended\", margin_titles=True)\n",
    "bins = np.linspace(0, 10, 10)\n",
    "g.map(plt.hist, \"overall_rating\", color=\"steelblue\", bins=bins)\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Not Recommended\")\n",
    "axes[1].set_title(\"Recommended\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Overall Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating by value money rated. This is obviously expected\n",
    "g = sns.FacetGrid(airline_completecase, col=\"recommended\", margin_titles=True)\n",
    "bins = np.linspace(0, 5, 5)\n",
    "g.map(plt.hist, \"value_money_rating\", color=\"steelblue\", bins=bins)\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Not Recommended\")\n",
    "axes[1].set_title(\"Recommended\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Value Money Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_completecase['recommended'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots of median overall and value money rating by whether or not reviewere recommended airline\n",
    "f, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "sns.boxplot(x=airline_completecase['recommended'], y=airline_completecase['overall_rating'],  ax=axes[0])\n",
    "axes[0].set_title(\"Median Overall Rating\")\n",
    "axes[0].set_xticklabels([\"No\",\"Yes\"])\n",
    "axes[0].set_xlabel(\"Recommend Airline?\")\n",
    "axes[0].set_ylabel(\"Overall Rating\")\n",
    "\n",
    "sns.boxplot(x=airline_completecase['recommended'], y=airline_completecase['value_money_rating'],  ax=axes[1])\n",
    "axes[1].set_title(\"Median Value Money Rating\")\n",
    "axes[1].set_xticklabels([\"No\",\"Yes\"])\n",
    "axes[1].set_xlabel(\"Recommend Airline?\")\n",
    "axes[1].set_ylabel(\"Value for Money Rating\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median ratings by recommended\n",
    "airline_completecase.groupby('recommended').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean ratings by recommended\n",
    "airline_completecase.groupby('recommended').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length of review vs recommended or not\n",
    "g = sns.FacetGrid(airline_completecase, col=\"recommended\", margin_titles=True, height=6)\n",
    "bins = 100\n",
    "g.map(plt.hist, \"length\", color=\"steelblue\", bins=bins)\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Not Recommended\")\n",
    "axes[1].set_title(\"Recommended\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Length of Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploratory look \n",
    "airline_completecase.groupby('recommended').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now getting into NLP with NLTK! We will analyze the reviews and see if they predict whether the reviewer recommends the airlines\n",
    "\n",
    "Special thanks to the Python for Data Science and Machine Learning Bootcamp by Jose Portilla at Udemy.com, since I used that lecture to set this up<br>\n",
    "<br>\n",
    "Class link here: https://www.udemy.com/python-for-data-science-and-machine-learning-bootcamp/learn/v4/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get set up for NLP using NLTK\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msg_train.iloc[111])  #check out a few full reviews to get a feeel for what they look like\n",
    "print(\"\")\n",
    "print(msg_train.iloc[535])\n",
    "print(\"\")\n",
    "print(msg_train.iloc[904])\n",
    "print(\"\")\n",
    "print(msg_train.iloc[5678])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing\n",
    "Our data is all in text format (strings). We will need to change this to some sort of numerical feaeture so that we can work with it. The simplest version is to use the bag-of-words approach, where each unique word in a text is represented by a number. We will convert the raw messages into vectors.<br>\n",
    "<br>\n",
    "\n",
    "We will start off by writing a function that splits a message into its individual words (returns a list), we will remove punctuation using the Python string library and remove common words using the NLTK library stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "print(\"string imported\")\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show some stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[0:10] # Show some stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting together a funtion to apply to our airlines data\n",
    "\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization: converting each message into a vector that machine learning models can understand.\n",
    "\n",
    "This will be done in three steps using the bag-of-words model:<br>\n",
    "1. Count how many times does a word occur in each message (Known as term frequency)<br>\n",
    "2. Weigh the counts, so that frequent tokens get lower weight (inverse document frequency)<br>\n",
    "3. Normalize the vectors to unit length, to abstract from the original text length (L2 norm)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF: applying term weighting and normalization\n",
    "\n",
    "We will now apply TF-IDF (term frequency-inverse document frequency), and the tf-idf weight is a weight often used in information retrieval and text mining. The more frequently a word appears, the lower its weight will be and vice versa.<br>\n",
    "<br>\n",
    "TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:<br>\n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).<br>\n",
    "\n",
    "IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:<br>\n",
    "\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model: Naive Bayes classifier algorithm\n",
    "\n",
    "Now that everything is represented as a vector, we can finally start to train our classifier. Naive Bayes classifier is a good place to start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a data pipeline\n",
    "We will run our model and then predict off the test set, using the SciKit Learn's pipeline capabilities to store a pipeline of workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipepine to do it all, same processes as before (this is identical to the same section on \n",
    "#NLP in the Udemy course jupyter notebook)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "print('pipeline built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with the training data\n",
    "pipeline.fit(msg_train,label_train)\n",
    "print('done yay!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now use the test data\n",
    "predictions = pipeline.predict(msg_test)\n",
    "\n",
    "print('done yay!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see how well it did\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predictions,label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some thoughts\n",
    "\n",
    "Precision: True positives/(True positives + false positives)<br>\n",
    "Recall: True positives/(True positives + false negatives)<br>\n",
    "<br>\n",
    "Our precision for the \"Yes\" predictions is pretty high, this is pretty nice. However, our precision for the \"No\" predictions comes out not nearly as nice. That being said, it is important in this case that we are able to have high precision in the \"yes\" column since this minimizes false positives. As something like this might be used to predict revenue from airline ticket sales, false positives may lead one to miss their revenue targets, which can be problematic for an airline's bottom line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at our results\n",
    "print(predictions[0:10]) # predictions from the pipeline\n",
    "print(label_test)  #what it was labelled at the outset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's do a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(label_test, predictions)  #prediction matrix\n",
    "cnf_matrix  #print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['No', 'Yes']\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cnf_matrix)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis on airline ratings data\n",
    "We can also analyze the structured data that is present here. Since there is so much missing data for maany of the ratings, we will focus upon the overall rating, value for money rating, cabin flown, and if the airline was recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#back to airline_completecase \n",
    "#what are the list of countries represeted\n",
    "countries_list=airline_completecase.author_country.unique()\n",
    "countries_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion that flew in which cabin\n",
    "airline_completecase['cabin_flown'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some exploratory figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cabin flown \n",
    "ax=sns.countplot(x='cabin_flown', data=airline_completecase)\n",
    "ax.set_title(\"Overall Rating by Cabin Flown\")\n",
    "ax.set_xlabel(\"Cabin Flown\")\n",
    "ax.set_ylabel(\"Number of Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of overall ratings\n",
    "ax=sns.distplot(airline_completecase.overall_rating, bins=10, kde=False, rug=False);\n",
    "ax.set_title(\"Histogram of Overall Ratings\")\n",
    "ax.set_xlabel(\"Overall Rating\")\n",
    "ax.set_ylabel(\"Number of Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating by recommend or not. This is obviously expected\n",
    "sns.set(style=\"darkgrid\")\n",
    "g = sns.FacetGrid(airline_completecase, col=\"recommended\", margin_titles=True)\n",
    "bins = np.linspace(0, 10, 10)\n",
    "g.map(plt.hist, \"overall_rating\", color=\"steelblue\", bins=bins)\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Not Recommended\")\n",
    "axes[1].set_title(\"Recommended\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Overall Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating by recommend or not. This is obviously expected\n",
    "sns.set(style=\"darkgrid\")\n",
    "g = sns.FacetGrid(airline_completecase, col=\"recommended\", margin_titles=True)\n",
    "bins = np.linspace(0, 5, 5)\n",
    "g.map(plt.hist, \"value_money_rating\", color=\"steelblue\", bins=bins)\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Not Recommended\")\n",
    "axes[1].set_title(\"Recommended\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Value Money Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating by cabin flown \n",
    "sns.set(style=\"darkgrid\")\n",
    "g = sns.FacetGrid(airline_completecase, col=\"cabin_flown\", margin_titles=True)\n",
    "bins = np.linspace(0, 10, 10)\n",
    "g.map(plt.hist, \"overall_rating\", color=\"steelblue\", bins=bins)\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Economy\")\n",
    "axes[1].set_title(\"Business Class\")\n",
    "axes[2].set_title(\"Premium Economy\")\n",
    "axes[3].set_title(\"First Class\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Overall Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating by cabin flown \n",
    "sns.set(style=\"darkgrid\")\n",
    "g = sns.FacetGrid(airline_completecase, col=\"cabin_flown\", margin_titles=True)\n",
    "bins = np.linspace(0, 5, 5)\n",
    "g.map(plt.hist, \"value_money_rating\", color=\"steelblue\", bins=bins)\n",
    "axes = g.axes.flatten()\n",
    "axes[0].set_title(\"Economy\")\n",
    "axes[1].set_title(\"Business Class\")\n",
    "axes[2].set_title(\"Premium Economy\")\n",
    "axes[3].set_title(\"First Class\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Value Money Rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What airlines are most represented here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby carrier to look at how things rank by carrier\n",
    "airlines_carrier=airline_completecase['airline_name'].value_counts()\n",
    "airlines_carrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_carrier[airlines_carrier>100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median by airline carriers\n",
    "airlines_grouped_median=airline_completecase.groupby('airline_name').median()\n",
    "#preliminary rank by carrier, but will need to restrict to like those with 100+ reviews only \n",
    "airlines_grouped_median.sort_values(by='overall_rating', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It looks like we will need to subset our data to the more popular airlines with >100 reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset only by airlines with >100 reviews \n",
    "airlines_carrier=airline_completecase['airline_name'].value_counts()  #counts of airline carrier\n",
    "airlines_subset=airlines_grouped_median[airlines_carrier>100]  #subset to those with >100 reviews\n",
    "airlines_subset.sort_values(by='overall_rating', ascending=False)   #mediannprint out overall ratings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the  list  of airlines that have >100 reviews\n",
    "#we will use this for the dictionary to generate country of origin\n",
    "pd.options.display.max_seq_items = 150\n",
    "print(str(airlines_carrier[airlines_carrier>100].index))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary containing airlines and country of origin (done manually outside of python since there isnt a consistent rule regarding this that I can have a computer do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_dict={\n",
    "    'british-airways' : 'United Kingdom' ,\n",
    "    'united-airlines' : 'United States' ,\n",
    "    'air-canada-rouge' : 'Canada' ,\n",
    "    'emirates' : 'United Arab Emirates' ,\n",
    "    'american-airlines' : 'United States' ,\n",
    "    'lufthansa' : 'Germany' ,\n",
    "    'qantas-airways' : 'Australia' ,\n",
    "    'jet-airways' : 'India' ,\n",
    "    'ryanair' : 'United Kingdom' ,\n",
    "    'etihad-airways' : 'United Arab Emirates' ,\n",
    "    'cathay-pacific-airways' : 'Hong Kong' ,\n",
    "    'qatar-airways' : 'Qatar' ,\n",
    "    'air-canada' : 'Canada' ,\n",
    "    'turkish-airlines' : 'Turkey' ,\n",
    "    'malaysia-airlines' : 'Malaysia' ,\n",
    "    'virgin-atlantic-airways' : 'United Kingdom' ,\n",
    "    'singapore-airlines' : 'Singapore' ,\n",
    "    'china-southern-airlines' : 'China' ,\n",
    "    'air-france' : 'France' ,\n",
    "    'delta-air-lines' : 'United States' ,\n",
    "    'easyjet' : 'United Kingdom' ,\n",
    "    'aer-lingus' : 'Ireland' ,\n",
    "    'norwegian' : 'Norway' ,\n",
    "    'sunwing-airlines' : 'Canada' ,\n",
    "    'thomson-airways' : 'United Kingdom' ,\n",
    "    'virgin-australia' : 'Australia' ,\n",
    "    'Thai-airways' : 'Thailand' ,\n",
    "    'garuda-indonesia' : 'Indonesia' ,\n",
    "    'klm-royal-dutch-airlines' : 'Netherlands' ,\n",
    "    'finnair' : 'Finland' ,\n",
    "    'swiss-international-air-lines' : 'Switzerland' ,\n",
    "    'southwest-airlines' : 'United States' ,\n",
    "    'thomas-cook-airlines' : 'United Kingdom' ,\n",
    "    'allegiant-air' : 'United States' ,\n",
    "    'tap-portugal' : 'Portugal' ,\n",
    "    'iberia' : 'Spain' ,\n",
    "    'asiana-airlines' : 'South Korea' ,\n",
    "    'jet2-com' : 'United Kingdom' ,\n",
    "    'korean-air' : 'South Korea' ,\n",
    "    'eva-air' : 'Taiwan' ,\n",
    "    'air-transat' : 'Canada' ,\n",
    "    'air-india' : 'India' ,\n",
    "    'alitalia' : 'Italy' ,\n",
    "    'airasia' : 'Malaysia' ,\n",
    "    'spirit-airlines' : 'United States' ,\n",
    "    'jetstar-airways' : 'Australia' ,\n",
    "    'air-new-zealand' : 'New Zealand' ,\n",
    "    'srilankan-airlines' : 'Sri Lanka' ,\n",
    "    'sas-scandinavian-airlines' : 'Sweden' ,\n",
    "    'china-eastern-airlines' : 'China' ,\n",
    "    'air-berlin' : 'Germany' ,\n",
    "    'ana-all-nippon-airways' : 'Japan' ,\n",
    "    'vietnam-airlines' : 'Vietnam' ,\n",
    "    'us-airways' : 'United States' ,\n",
    "    'austrian-airlines' : 'Austria' ,\n",
    "    'royal-brunei-airlines' : 'Brunei' ,\n",
    "    'south-african-airways' : 'South Africa' ,\n",
    "    'lan-airlines' : 'Chile' ,\n",
    "    'philippine-airlines' : 'Philippines' ,\n",
    "    'icelandair' : 'Iceland' ,\n",
    "    'flybe' : 'United Kingdom' ,\n",
    "    'vueling-airlines' : 'Spain' ,\n",
    "    'monarch-airlines' : 'United Kingdom' ,\n",
    "    'aeroflot-russian-airlines' : 'Russian Federation' ,\n",
    "    'aegean-airlines' : 'Greece' ,\n",
    "    'wizz-air' : 'Hungary' ,\n",
    "    'frontier-airlines' : 'United States' ,\n",
    "    'virgin-america' : 'United States' ,\n",
    "    'air-china' : 'China' ,\n",
    "    'hawaiian-airlines' : 'United States' ,\n",
    "    'alaska-airlines' : 'United States' ,\n",
    "    'tigerair' : 'Australia' ,\n",
    "    'egyptair' : 'Egypt' ,\n",
    "    'china-airlines' : 'China' ,\n",
    "    'brussels-airlines' : 'Belgium' ,\n",
    "    'bangkok-airways' : 'Thailand' ,\n",
    "    'tam-airlines' : 'Brazil' ,\n",
    "    'ethiopian-airlines' : 'Ethiopia' ,\n",
    "    'oman-air' : 'Oman' ,\n",
    "    'japan-airlines' : 'Japan' ,\n",
    "    'airasia-x' : 'Malaysia' ,\n",
    "    'fiji-airways' : 'Fiji' ,\n",
    "    'royal-jordanian-airlines' : 'Jordan' ,\n",
    "    'aerolineas-argentinas' : 'Argentina' ,\n",
    "    'gulf-air' : 'Bahrain' ,\n",
    "    'lot-polish-airlines' : 'Poland' ,\n",
    "    'kenya-airways' : 'Kenya' ,\n",
    "    'avianca' : 'Colombia' ,\n",
    "    'continental-airlines' : 'United States' ,\n",
    "    'condor-airlines' : 'Germany' ,\n",
    "    'air-europa' : 'Spain' ,\n",
    "    'dragonair' : 'Hong Kong' ,\n",
    "    'bmi-british-midland-international' : 'United Kingdom' ,\n",
    "    'scoot' : 'Singapore' ,\n",
    "    'silkair' : 'Singapore' ,\n",
    "    'royal-air-maroc' : 'Morocco' ,\n",
    "    'el-al-israel-airlines' : 'Israel' ,\n",
    "    'aeromexico' : 'Mexico' ,\n",
    "    'saudi-arabian-airlines' : 'Saudi Arabia' ,\n",
    "    'pegasus-airlines' : 'Turkey' ,\n",
    "    'indigo-airlines' : 'India' ,\n",
    "    'air-astana' : 'Kazakhstan' ,\n",
    "    'copa-airlines' : 'Panama' ,\n",
    "    'kuwait-airways ' : 'Kuwait'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#airlines_subset\n",
    "#now we have to go and assign these to the carriers\n",
    "#note that those where airline_country is missing are those who are not included in final set \n",
    "#to do this, we will definitely have to go back to the original dataset airlines_complete case and rerun these things\n",
    "airline_completecase['airline_country']=airline_completecase['airline_name'].map(airline_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check this out to see if it checks out\n",
    "airline_completecase.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out the ones for BA to see that this checks out\n",
    "airline_completecase[airline_completecase['airline_name']=='british-airways']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out the ones for adria to see that this checks out : Adria should not have a country assigned \n",
    "airline_completecase[airline_completecase['airline_name']=='adria-airways']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go get rid of missings in airline_completecase\n",
    "print(\"we are now dropping reviews from airlines with less than 100 reviews from airline_completecase and saving in a new dataset called airline_short\")\n",
    "airline_short = airline_completecase.dropna()\n",
    "#how many?\n",
    "print('we have '+ str(len(airline_short)) + ' complete case observations in this subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_short.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_short.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's sort by countries!!\n",
    "#median by airline carriers\n",
    "airlines_median=airline_short.groupby('airline_country').median()\n",
    "#preliminary rank by carrier, but will need to restrict to like those with 100+ reviews only \n",
    "medsort=airlines_median.sort_values(by='overall_rating', ascending=False)\n",
    "medsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_short['airline_country'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 50))\n",
    "sns.barplot(x=\"overall_rating\", y=medsort.index, data=medsort,\n",
    "            label=\"Overall\", color=\"b\")\n",
    "# Add a legend and informative axis label\n",
    "ax.set_title('Median Ratings by Airline Country of Origin')\n",
    "ax.set(xlim=(0, 10), ylabel=\"Country of Airline\",\n",
    "       xlabel=\"Rating\")\n",
    "plt.savefig(\"ratingsbycountry.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do just for the US\n",
    "\n",
    "#now let us subset by US carriers only\n",
    "us_airlines=airline_short[airline_short['airline_country']==\"United States\"].groupby('airline_name').median()\n",
    "#sort by descenting rating \n",
    "us_ranked=us_airlines.sort_values(by='overall_rating', ascending=False)\n",
    "us_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 18))\n",
    "sns.barplot(x=\"overall_rating\", y=us_ranked.index, data=us_ranked,\n",
    "            label=\"Overall\", color=\"b\")\n",
    "# Add a legend and informative axis label\n",
    "ax.set_title('Median Ratings of US Airlines')\n",
    "ax.set(xlim=(0, 10), ylabel=\"Airline\",\n",
    "       xlabel=\"Rating\")\n",
    "plt.savefig(\"usratingsbycarrier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get percent recommended\n",
    "#recommended is a dichotomous variable coded 0, 1, a mean of these will give you a proportion that would \n",
    "#recommend this airline\n",
    "rec_frac=airline_short[airline_short['airline_country']==\"United States\"].groupby('airline_name').mean()  \n",
    "rec_sort=rec_frac.sort_values(by='recommended', ascending=False)\n",
    "rec_sort['recommended']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiply recommended by 100 for percentage\n",
    "rec_sort['rec_pct']=rec_sort['recommended']*100\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 18))\n",
    "sns.barplot(x=\"rec_pct\", y=rec_sort.index, data=rec_sort,\n",
    "            label=\"Overall\", color=\"b\")\n",
    "# Add a legend and informative axis label\n",
    "ax.set_title('Average Ratings of US Airlines')\n",
    "ax.set(xlim=(0, 100), ylabel=\"Airline\",\n",
    "       xlabel=\"Percent that would Recommend\")\n",
    "plt.savefig(\"usrecs_bycarrier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
